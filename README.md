# BeyondChats â€“ Full Stack Web Developer Intern Assignment

## ğŸ“Œ Project Overview

This project was developed as part of the **BeyondChats Full Stack Web Developer Intern assignment**.
The goal of the assignment is to build an **end-to-end content automation system** that:

1. Scrapes blog articles from BeyondChats
2. Stores them in a database with CRUD APIs
3. Enhances articles using Google Search + LLM (AI)
4. Displays original and updated articles in a professional frontend UI

The project is divided into **three phases**, as required.

---

## ğŸ§± Tech Stack

### Backend

* Node.js
* Express.js
* MongoDB + Mongoose
* Axios
* Cheerio (web scraping)
* SerpAPI (Google Search)
* OpenAI API (LLM for content enhancement)

### Frontend

* React.js (Vite)
* Axios
* CSS (responsive & minimal UI)

### Tools

* Git & GitHub
* Postman (API testing)

---

## ğŸ“‚ Project Structure

```
beyondchats-assignment/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ Article.js
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â””â”€â”€ articleController.js
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ articleRoutes.js
â”‚   â”‚   â”‚   â””â”€â”€ scrapeRoutes.js
â”‚   â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”‚   â””â”€â”€ blogScraper.js
â”‚   â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”‚   â””â”€â”€ updateArticles.js
â”‚   â”‚   â””â”€â”€ app.js
â”‚   â”‚
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ package.json
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ ArticleCard.jsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ Home.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ .env
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

---

## ğŸš€ Phase 1 â€“ Scraping & CRUD APIs

### Features

* Scrapes **5 oldest blog articles** from BeyondChats
* Extracts:

  * Title
  * Full content
  * Source URL
* Stores articles in MongoDB
* Provides full **CRUD APIs**

### API Endpoints

| Method | Endpoint            | Description              |
| ------ | ------------------- | ------------------------ |
| GET    | `/api/articles`     | Get all articles         |
| GET    | `/api/articles/:id` | Get single article       |
| POST   | `/api/articles`     | Create article           |
| PUT    | `/api/articles/:id` | Update article           |
| DELETE | `/api/articles/:id` | Delete article           |
| POST   | `/api/scrape`       | Scrape BeyondChats blogs |

---

## ğŸ¤– Phase 2 â€“ Automation Script (Google + AI)

### Description

A Node.js automation script that:

1. Fetches articles using backend APIs
2. Searches article titles on Google using SerpAPI
3. Selects top 2 non-BeyondChats articles
4. Scrapes their main content
5. Uses an LLM (OpenAI) to rewrite the original article
6. Publishes the updated article via CRUD APIs
7. Appends reference links at the bottom

### Important Note on LLM Usage

Due to **API quota limitations**, the script demonstrates the **complete automation pipeline** on a limited number of articles.
The logic is fully scalable and supports updating all articles once sufficient API quota is available.

This limitation is external to the application and does not affect the correctness of the implementation.

---

## ğŸ–¥ï¸ Phase 3 â€“ React Frontend

### Features

* Fetches articles from backend APIs
* Displays:

  * Original article content
  * Updated (AI-generated) article content
* Toggle between original and updated versions
* Responsive and professional UI

---

## ğŸ” Data Flow / Architecture

```
BeyondChats Blog
        â†“
Web Scraper (Cheerio)
        â†“
MongoDB Database
        â†“
CRUD APIs (Express)
        â†“
Automation Script
  â”œâ”€ Google Search (SerpAPI)
  â”œâ”€ Content Scraping
  â”œâ”€ LLM (OpenAI)
        â†“
Updated Articles Stored
        â†“
React Frontend UI
```

---

## âš™ï¸ Local Setup Instructions

### 1ï¸âƒ£ Backend Setup

```bash
cd backend
npm install
```

Create `.env` file:

```env
PORT=5000
MONGO_URI=mongodb://127.0.0.1:27017/beyondchats
SERP_API_KEY=your_serpapi_key
OPENAI_API_KEY=your_openai_api_key
```

Run backend:

```bash
npx nodemon src/app.js
```

---

### 2ï¸âƒ£ Scrape Articles (Phase 1)

```http
POST http://localhost:5000/api/scrape
```

---

### 3ï¸âƒ£ Run Automation Script (Phase 2)

> Backend must be running

```bash
node src/scripts/updateArticles.js
```

---

### 4ï¸âƒ£ Frontend Setup (Phase 3)

```bash
cd frontend
npm install
```

Create `.env`:

```env
VITE_API_URL=http://localhost:5000/api
```

Run frontend:

```bash
npm run dev
```

Open:

```
http://localhost:5173
```

---

## ğŸ§ª Testing

* APIs tested using Postman
* Frontend tested manually in browser
* Script logs confirm successful automation flow

---

## ğŸ“ˆ Evaluation Criteria Mapping

| Criteria      | Covered                    |
| ------------- | -------------------------- |
| Completeness  | âœ… All 3 phases implemented |
| ReadMe & Docs | âœ… Detailed README          |
| UI/UX         | âœ… Clean & responsive       |
| Live Link     | ğŸ”² Ready for deployment    |
| Code Quality  | âœ… Modular & readable       |

---

## ğŸ§  Key Learnings

* Real-world web scraping challenges
* API-driven automation pipelines
* LLM integration in backend workflows
* Handling third-party API limitations gracefully
* Full-stack data flow design

---

## ğŸ‘¤ Author

**Shrutika Deshmukh**

---

